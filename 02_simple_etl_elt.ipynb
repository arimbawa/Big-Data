{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arimbawa/Big-Data/blob/main/02_simple_etl_elt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "Jia-qbmKiS1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hbAQTNcdjkm",
        "outputId": "a39ed654-dda0-433b-ba2a-237db5e5ba33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            timestamp sensor_id  temperature  humidity  light\n",
            "0 2025-09-06 08:00:00  sensor_1        28.84     63.19    732\n",
            "1 2025-09-06 08:00:00  sensor_2        32.52     66.43    799\n",
            "2 2025-09-06 08:00:00  sensor_3        30.49     66.14    419\n",
            "3 2025-09-06 08:00:00  sensor_4        27.65     40.94    219\n",
            "4 2025-09-06 08:00:00  sensor_5        28.72     65.31    739\n",
            "5 2025-09-06 08:01:00  sensor_1        34.42     47.26    789\n",
            "6 2025-09-06 08:01:00  sensor_2        31.93     58.76    250\n",
            "7 2025-09-06 08:01:00  sensor_3        32.57     55.04    203\n",
            "8 2025-09-06 08:01:00  sensor_4        29.85     54.89    324\n",
            "9 2025-09-06 08:01:00  sensor_5        28.78     58.37    304\n",
            "\n",
            "Data sensor berhasil dibuat dan disimpan ke sensor_data.csv\n"
          ]
        }
      ],
      "source": [
        "# === Konfigurasi simulasi ===\n",
        "n_sensors = 5                 # jumlah sensor\n",
        "n_minutes = 120               # jumlah menit data (2 jam)\n",
        "start_time = datetime(2025, 9, 6, 8, 0)  # jam mulai\n",
        "\n",
        "# daftar sensor_id\n",
        "sensor_ids = [f\"sensor_{i+1}\" for i in range(n_sensors)]\n",
        "\n",
        "# === Generate data ===\n",
        "timestamps = [start_time + timedelta(minutes=i) for i in range(n_minutes)]\n",
        "data = []\n",
        "\n",
        "np.random.seed(24453)\n",
        "for ts in timestamps:\n",
        "    for sid in sensor_ids:\n",
        "        temperature = round(np.random.normal(30, 2), 2)   # suhu (Â°C)\n",
        "        humidity = round(np.random.uniform(40, 70), 2)    # kelembapan (%)\n",
        "        light = np.random.randint(200, 800)               # intensitas cahaya (lux)\n",
        "        data.append([ts, sid, temperature, humidity, light])\n",
        "\n",
        "# === Buat DataFrame ===\n",
        "df = pd.DataFrame(data, columns=[\"timestamp\", \"sensor_id\", \"temperature\", \"humidity\", \"light\"])\n",
        "\n",
        "print(df.head(10))  # tampilkan 10 baris pertama\n",
        "\n",
        "# Simpan ke CSV (opsional)\n",
        "df.to_csv(\"sensor_data.csv\", index=False)\n",
        "print(\"\\nData sensor berhasil dibuat dan disimpan ke sensor_data.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3"
      ],
      "metadata": {
        "id": "BHeihIg2iIxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline Sederhana di Python (ETL)"
      ],
      "metadata": {
        "id": "C6WP4E0Pfq9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1. Extract ===\n",
        "df = pd.read_csv(\"sensor_data.csv\")\n",
        "# contoh kolom: timestamp, sensor_id, temperature\n",
        "\n",
        "# === 2. Transform ===\n",
        "# ubah timestamp ke datetime\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "# hitung rata-rata suhu per jam\n",
        "df_hourly = df.set_index('timestamp').groupby(['sensor_id']).resample('1h').mean().reset_index()\n",
        "\n",
        "# === 3. Load ===\n",
        "conn = sqlite3.connect(\"warehouse.db\")\n",
        "df_hourly.to_sql(\"sensor_hourly\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "print(\"ETL selesai! Data masuk ke SQLite warehouse.\")\n",
        "df_result = pd.read_sql(\"SELECT * FROM sensor_hourly\", conn)\n",
        "print(df_result.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IYgnkqbdwTm",
        "outputId": "be91eb89-cf19-445a-bc3e-58cb1240660b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ETL selesai! Data masuk ke SQLite warehouse.\n",
            "  sensor_id            timestamp  temperature   humidity       light\n",
            "0  sensor_1  2025-09-06 08:00:00    30.004667  54.517333  504.833333\n",
            "1  sensor_1  2025-09-06 09:00:00    29.230000  55.197333  506.216667\n",
            "2  sensor_2  2025-09-06 08:00:00    30.388167  55.244833  511.983333\n",
            "3  sensor_2  2025-09-06 09:00:00    29.671500  55.550833  528.066667\n",
            "4  sensor_3  2025-09-06 08:00:00    29.558833  56.734667  473.433333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline Sederhana di Python (ELT)"
      ],
      "metadata": {
        "id": "nAdtNedrfopi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1. Extract ===\n",
        "df = pd.read_csv(\"sensor_data.csv\")\n",
        "\n",
        "# === 2. Load (langsung raw data) ===\n",
        "conn = sqlite3.connect(\"warehouse_raw.db\")\n",
        "df.to_sql(\"sensor_raw\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "# === 3. Transform (di dalam DW dengan SQL) ===\n",
        "query = \"\"\"\n",
        "CREATE TABLE sensor_hourly AS\n",
        "SELECT sensor_id,\n",
        "       strftime('%Y-%m-%d %H:00:00', timestamp) AS hour,\n",
        "       AVG(temperature) AS avg_temp,\n",
        "       AVG(humidity) AS avg_hum,\n",
        "       AVG(light) AS avg_light\n",
        "FROM sensor_raw\n",
        "GROUP BY sensor_id, hour;\n",
        "\"\"\"\n",
        "conn.execute(\"DROP TABLE IF EXISTS sensor_hourly;\")\n",
        "conn.execute(query)\n",
        "print(\"ELT selesai! Data raw + transformasi ada di SQLite warehouse.\")\n",
        "\n",
        "df_result = pd.read_sql(\"SELECT * FROM sensor_hourly\", conn)\n",
        "print(df_result.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zoyKOmifGUN",
        "outputId": "8960625e-0715-4771-a525-f42b81d63fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ELT selesai! Data raw + transformasi ada di SQLite warehouse.\n",
            "  sensor_id                 hour   avg_temp    avg_hum   avg_light\n",
            "0  sensor_1  2025-09-06 08:00:00  30.004667  54.517333  504.833333\n",
            "1  sensor_1  2025-09-06 09:00:00  29.230000  55.197333  506.216667\n",
            "2  sensor_2  2025-09-06 08:00:00  30.388167  55.244833  511.983333\n",
            "3  sensor_2  2025-09-06 09:00:00  29.671500  55.550833  528.066667\n",
            "4  sensor_3  2025-09-06 08:00:00  29.558833  56.734667  473.433333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline Python Smart City"
      ],
      "metadata": {
        "id": "Q7ESJKAvhaBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1. Simulasi Big Data (Extract) ===\n",
        "# Buat data sensor lalu lintas acak untuk 3 lokasi selama 1 hari\n",
        "np.random.seed(42)\n",
        "start_time = datetime(2025, 9, 6, 0, 0)\n",
        "timestamps = [start_time + timedelta(minutes=i) for i in range(24*60)]  # 1 hari, per menit\n",
        "locations = [\"Jl. Majapahit\", \"Jl. Sriwijaya\", \"Jl. Airlangga\"]\n",
        "\n",
        "data = []\n",
        "for ts in timestamps:\n",
        "    for loc in locations:\n",
        "        vehicles = np.random.poisson(lam=np.random.randint(0,70))  # distribusi acak jumlah kendaraan\n",
        "        data.append([ts, loc, vehicles])\n",
        "\n",
        "df_raw = pd.DataFrame(data, columns=[\"timestamp\", \"location\", \"vehicles\"])\n",
        "\n",
        "# === 2. Load ke Data Warehouse (SQLite) ===\n",
        "conn = sqlite3.connect(\"smartcity_dw.db\")\n",
        "df_raw.to_sql(\"traffic_raw\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "# === 3. Transformasi & Analisis (di DW) ===\n",
        "query = \"\"\"\n",
        "CREATE TABLE traffic_hourly AS\n",
        "SELECT location,\n",
        "       strftime('%Y-%m-%d %H:00:00', timestamp) AS hour,\n",
        "       AVG(vehicles) AS avg_vehicles\n",
        "FROM traffic_raw\n",
        "GROUP BY location, hour;\n",
        "\"\"\"\n",
        "conn.execute(\"DROP TABLE IF EXISTS traffic_hourly;\")\n",
        "conn.execute(query)\n",
        "\n",
        "# Ambil hasil analisis\n",
        "df_result = pd.read_sql(\"SELECT * FROM traffic_hourly\", conn)\n",
        "\n",
        "print(\"Contoh hasil analisis (5 baris pertama):\")\n",
        "print(df_result.head())\n",
        "\n",
        "# Simulasi Smart City Insight\n",
        "jam_macet = df_result[df_result[\"avg_vehicles\"] > 30]\n",
        "print(\"\\nJam rawan macet terdeteksi:\")\n",
        "print(jam_macet.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWmsQnYpfk4-",
        "outputId": "041b6c02-4d92-44f1-c1ed-da9602097736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contoh hasil analisis (5 baris pertama):\n",
            "        location                 hour  avg_vehicles\n",
            "0  Jl. Airlangga  2025-09-06 00:00:00     34.366667\n",
            "1  Jl. Airlangga  2025-09-06 01:00:00     37.200000\n",
            "2  Jl. Airlangga  2025-09-06 02:00:00     29.200000\n",
            "3  Jl. Airlangga  2025-09-06 03:00:00     38.883333\n",
            "4  Jl. Airlangga  2025-09-06 04:00:00     39.783333\n",
            "\n",
            "Jam rawan macet terdeteksi:\n",
            "        location                 hour  avg_vehicles\n",
            "0  Jl. Airlangga  2025-09-06 00:00:00     34.366667\n",
            "1  Jl. Airlangga  2025-09-06 01:00:00     37.200000\n",
            "3  Jl. Airlangga  2025-09-06 03:00:00     38.883333\n",
            "4  Jl. Airlangga  2025-09-06 04:00:00     39.783333\n",
            "5  Jl. Airlangga  2025-09-06 05:00:00     31.350000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perempatan Taman Aji macet karena ketiga lokasi macet\n",
        "# Find hours where all 3 locations have avg_vehicles > 30\n",
        "congested_hours_all_locations = df_result[df_result['avg_vehicles'] > 35].groupby('hour').size() == 3\n",
        "print(\"\\nJam di mana ketiga lokasi memiliki rata-rata kendaraan > 30 secara bersamaan:\")\n",
        "print(congested_hours_all_locations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Akh6xdZ8uCvt",
        "outputId": "cb4d8b80-5a08-463a-e380-5a2060594988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Jam di mana ketiga lokasi memiliki rata-rata kendaraan > 30 secara bersamaan:\n",
            "hour\n",
            "2025-09-06 00:00:00    False\n",
            "2025-09-06 01:00:00    False\n",
            "2025-09-06 02:00:00    False\n",
            "2025-09-06 03:00:00    False\n",
            "2025-09-06 04:00:00     True\n",
            "2025-09-06 05:00:00    False\n",
            "2025-09-06 06:00:00    False\n",
            "2025-09-06 07:00:00    False\n",
            "2025-09-06 08:00:00    False\n",
            "2025-09-06 09:00:00    False\n",
            "2025-09-06 10:00:00     True\n",
            "2025-09-06 11:00:00    False\n",
            "2025-09-06 12:00:00    False\n",
            "2025-09-06 13:00:00    False\n",
            "2025-09-06 14:00:00    False\n",
            "2025-09-06 15:00:00    False\n",
            "2025-09-06 16:00:00    False\n",
            "2025-09-06 17:00:00     True\n",
            "2025-09-06 18:00:00    False\n",
            "2025-09-06 19:00:00    False\n",
            "2025-09-06 21:00:00    False\n",
            "2025-09-06 22:00:00    False\n",
            "2025-09-06 23:00:00    False\n",
            "dtype: bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Simulasi Flood Prediction (ELT) ===\n",
        "# Simulate water depth data for sensors in three rivers: Jangkok, Unus, Meninting\n",
        "np.random.seed(42)\n",
        "start_time = datetime(2025, 9, 6, 0, 0)\n",
        "timestamps = [start_time + timedelta(minutes=i) for i in range(48*60)]  # 2 day, per minute\n",
        "rivers = [\"Jangkok\", \"Unus\", \"Meninting\"]\n",
        "\n",
        "data = []\n",
        "for ts in timestamps:\n",
        "    for river in rivers:\n",
        "        # Simulate water depth with some fluctuations and potential peaks\n",
        "        base_depth = np.random.uniform(0.5, 1.5) # Base depth in meters\n",
        "        # Add some noise and potential flood peaks\n",
        "        water_depth = round(base_depth + np.random.normal(0, 0.2) + np.random.choice([0, 0, 0, 0, 0.5, 1.0, 1.5]), 2)\n",
        "        # Ensure depth is not negative\n",
        "        water_depth = max(0, water_depth)\n",
        "        data.append([ts, river, water_depth])\n",
        "\n",
        "df_raw_flood = pd.DataFrame(data, columns=[\"timestamp\", \"river\", \"water_depth\"])\n",
        "\n",
        "# === Load to Data Warehouse (SQLite) ===\n",
        "conn_flood = sqlite3.connect(\"flood_dw.db\")\n",
        "df_raw_flood.to_sql(\"water_depth_raw\", conn_flood, if_exists=\"replace\", index=False)\n",
        "\n",
        "# === Transform & Analyze (in DW) ===\n",
        "# Calculate hourly average water depth\n",
        "query_flood = \"\"\"\n",
        "CREATE TABLE water_depth_hourly AS\n",
        "SELECT river,\n",
        "       strftime('%Y-%m-%d %H:00:00', timestamp) AS hour,\n",
        "       AVG(water_depth) AS avg_water_depth\n",
        "FROM water_depth_raw\n",
        "GROUP BY river, hour;\n",
        "\"\"\"\n",
        "conn_flood.execute(\"DROP TABLE IF EXISTS water_depth_hourly;\")\n",
        "conn_flood.execute(query_flood)\n",
        "\n",
        "# Get analysis results\n",
        "df_result_flood = pd.read_sql(\"SELECT * FROM water_depth_hourly\", conn_flood)\n",
        "\n",
        "print(\"Contoh hasil analisis (5 baris pertama):\")\n",
        "print(df_result_flood.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYY_nwQ8XN6J",
        "outputId": "feaf23ba-028e-4271-d8d4-5ac293571e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contoh hasil analisis (5 baris pertama):\n",
            "     river                 hour  avg_water_depth\n",
            "0  Jangkok  2025-09-06 00:00:00         1.478667\n",
            "1  Jangkok  2025-09-06 01:00:00         1.545167\n",
            "2  Jangkok  2025-09-06 02:00:00         1.452833\n",
            "3  Jangkok  2025-09-06 03:00:00         1.475000\n",
            "4  Jangkok  2025-09-06 04:00:00         1.384833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flood alert condition when all of the three rivers' water depth are more than 1.5 m.\n",
        "# Find hours where all 3 rivers have avg_water_depth > 1.5\n",
        "flood_alert_all_rivers = df_result_flood[df_result_flood['avg_water_depth'] > 1.45].groupby('hour').size() == len(rivers)\n",
        "print(\"\\nJam di mana ketiga sungai memiliki rata-rata kedalaman air > 1.5m secara bersamaan:\")\n",
        "print(flood_alert_all_rivers[flood_alert_all_rivers])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZuIALQpb9fI",
        "outputId": "58789428-2964-4ebc-96f0-1b5654b6a84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Jam di mana ketiga sungai memiliki rata-rata kedalaman air > 1.5m secara bersamaan:\n",
            "hour\n",
            "2025-09-06 01:00:00    True\n",
            "2025-09-06 06:00:00    True\n",
            "2025-09-06 09:00:00    True\n",
            "2025-09-07 05:00:00    True\n",
            "2025-09-07 09:00:00    True\n",
            "2025-09-07 12:00:00    True\n",
            "dtype: bool\n"
          ]
        }
      ]
    }
  ]
}