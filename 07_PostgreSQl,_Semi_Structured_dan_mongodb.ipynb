{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arimbawa/Big-Data/blob/main/07_PostgreSQl%2C_Semi_Structured_dan_mongodb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PostgreSQL"
      ],
      "metadata": {
        "id": "41jImq6a59fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dan jalankan PostgreSQL\n",
        "!apt-get -y install postgresql postgresql-contrib\n",
        "!service postgresql start\n",
        "\n",
        "# Buat user dan database\n",
        "!sudo -u postgres psql -c \"CREATE USER colabuser WITH PASSWORD 'colabpass';\"\n",
        "!sudo -u postgres psql -c \"CREATE DATABASE colabdb OWNER colabuser;\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAZq8E5jwy32",
        "outputId": "b8ad3d8b-afe9-47e1-bafe-5e0a0053d73e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libcommon-sense-perl libjson-perl libjson-xs-perl libtypes-serialiser-perl\n",
            "  logrotate netbase postgresql-14 postgresql-client-14\n",
            "  postgresql-client-common postgresql-common ssl-cert sysstat\n",
            "Suggested packages:\n",
            "  bsd-mailx | mailx postgresql-doc postgresql-doc-14 isag\n",
            "The following NEW packages will be installed:\n",
            "  libcommon-sense-perl libjson-perl libjson-xs-perl libtypes-serialiser-perl\n",
            "  logrotate netbase postgresql postgresql-14 postgresql-client-14\n",
            "  postgresql-client-common postgresql-common postgresql-contrib ssl-cert\n",
            "  sysstat\n",
            "0 upgraded, 14 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 18.5 MB of archives.\n",
            "After this operation, 52.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 logrotate amd64 3.19.0-1ubuntu1.1 [54.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 netbase all 6.3 [12.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libcommon-sense-perl amd64 3.75-2build1 [21.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-perl all 4.04000-1 [81.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtypes-serialiser-perl all 1.01-1 [11.6 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libjson-xs-perl amd64 4.040-0ubuntu0.22.04.1 [87.0 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 postgresql-client-common all 238 [29.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 postgresql-client-14 amd64 14.19-0ubuntu0.22.04.1 [1,249 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 ssl-cert all 1.1.2 [17.4 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 postgresql-common all 238 [169 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 postgresql-14 amd64 14.19-0ubuntu0.22.04.1 [16.2 MB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 postgresql all 14+238 [3,288 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 postgresql-contrib all 14+238 [3,292 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.2 [487 kB]\n",
            "Fetched 18.5 MB in 3s (6,382 kB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package logrotate.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../00-logrotate_3.19.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking logrotate (3.19.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package netbase.\n",
            "Preparing to unpack .../01-netbase_6.3_all.deb ...\n",
            "Unpacking netbase (6.3) ...\n",
            "Selecting previously unselected package libcommon-sense-perl:amd64.\n",
            "Preparing to unpack .../02-libcommon-sense-perl_3.75-2build1_amd64.deb ...\n",
            "Unpacking libcommon-sense-perl:amd64 (3.75-2build1) ...\n",
            "Selecting previously unselected package libjson-perl.\n",
            "Preparing to unpack .../03-libjson-perl_4.04000-1_all.deb ...\n",
            "Unpacking libjson-perl (4.04000-1) ...\n",
            "Selecting previously unselected package libtypes-serialiser-perl.\n",
            "Preparing to unpack .../04-libtypes-serialiser-perl_1.01-1_all.deb ...\n",
            "Unpacking libtypes-serialiser-perl (1.01-1) ...\n",
            "Selecting previously unselected package libjson-xs-perl.\n",
            "Preparing to unpack .../05-libjson-xs-perl_4.040-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libjson-xs-perl (4.040-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package postgresql-client-common.\n",
            "Preparing to unpack .../06-postgresql-client-common_238_all.deb ...\n",
            "Unpacking postgresql-client-common (238) ...\n",
            "Selecting previously unselected package postgresql-client-14.\n",
            "Preparing to unpack .../07-postgresql-client-14_14.19-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking postgresql-client-14 (14.19-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package ssl-cert.\n",
            "Preparing to unpack .../08-ssl-cert_1.1.2_all.deb ...\n",
            "Unpacking ssl-cert (1.1.2) ...\n",
            "Selecting previously unselected package postgresql-common.\n",
            "Preparing to unpack .../09-postgresql-common_238_all.deb ...\n",
            "Adding 'diversion of /usr/bin/pg_config to /usr/bin/pg_config.libpq-dev by postgresql-common'\n",
            "Unpacking postgresql-common (238) ...\n",
            "Selecting previously unselected package postgresql-14.\n",
            "Preparing to unpack .../10-postgresql-14_14.19-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking postgresql-14 (14.19-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package postgresql.\n",
            "Preparing to unpack .../11-postgresql_14+238_all.deb ...\n",
            "Unpacking postgresql (14+238) ...\n",
            "Selecting previously unselected package postgresql-contrib.\n",
            "Preparing to unpack .../12-postgresql-contrib_14+238_all.deb ...\n",
            "Unpacking postgresql-contrib (14+238) ...\n",
            "Selecting previously unselected package sysstat.\n",
            "Preparing to unpack .../13-sysstat_12.5.2-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking sysstat (12.5.2-2ubuntu0.2) ...\n",
            "Setting up logrotate (3.19.0-1ubuntu1.1) ...\n",
            "Created symlink /etc/systemd/system/timers.target.wants/logrotate.timer ‚Üí /lib/systemd/system/logrotate.timer.\n",
            "Setting up libcommon-sense-perl:amd64 (3.75-2build1) ...\n",
            "Setting up ssl-cert (1.1.2) ...\n",
            "Setting up libtypes-serialiser-perl (1.01-1) ...\n",
            "Setting up libjson-perl (4.04000-1) ...\n",
            "Setting up netbase (6.3) ...\n",
            "Setting up sysstat (12.5.2-2ubuntu0.2) ...\n",
            "\n",
            "Creating config file /etc/default/sysstat with new version\n",
            "update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode\n",
            "Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer ‚Üí /lib/systemd/system/sysstat-collect.timer.\n",
            "Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer ‚Üí /lib/systemd/system/sysstat-summary.timer.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service ‚Üí /lib/systemd/system/sysstat.service.\n",
            "Setting up postgresql-client-common (238) ...\n",
            "Setting up libjson-xs-perl (4.040-0ubuntu0.22.04.1) ...\n",
            "Setting up postgresql-client-14 (14.19-0ubuntu0.22.04.1) ...\n",
            "update-alternatives: using /usr/share/postgresql/14/man/man1/psql.1.gz to provide /usr/share/man/man1/psql.1.gz (psql.1.gz) in auto mode\n",
            "Setting up postgresql-common (238) ...\n",
            "Adding user postgres to group ssl-cert\n",
            "\n",
            "Creating config file /etc/postgresql-common/createcluster.conf with new version\n",
            "Building PostgreSQL dictionaries from installed myspell/hunspell packages...\n",
            "Removing obsolete dictionary files:\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/postgresql.service ‚Üí /lib/systemd/system/postgresql.service.\n",
            "Setting up postgresql-14 (14.19-0ubuntu0.22.04.1) ...\n",
            "Creating new PostgreSQL cluster 14/main ...\n",
            "/usr/lib/postgresql/14/bin/initdb -D /var/lib/postgresql/14/main --auth-local peer --auth-host scram-sha-256 --no-instructions\n",
            "The files belonging to this database system will be owned by user \"postgres\".\n",
            "This user must also own the server process.\n",
            "\n",
            "The database cluster will be initialized with locale \"en_US.UTF-8\".\n",
            "The default database encoding has accordingly been set to \"UTF8\".\n",
            "The default text search configuration will be set to \"english\".\n",
            "\n",
            "Data page checksums are disabled.\n",
            "\n",
            "fixing permissions on existing directory /var/lib/postgresql/14/main ... ok\n",
            "creating subdirectories ... ok\n",
            "selecting dynamic shared memory implementation ... posix\n",
            "selecting default max_connections ... 100\n",
            "selecting default shared_buffers ... 128MB\n",
            "selecting default time zone ... Etc/UTC\n",
            "creating configuration files ... ok\n",
            "running bootstrap script ... ok\n",
            "performing post-bootstrap initialization ... ok\n",
            "syncing data to disk ... ok\n",
            "update-alternatives: using /usr/share/postgresql/14/man/man1/postmaster.1.gz to provide /usr/share/man/man1/postmaster.1.gz (postmaster.1.gz) in auto mode\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up postgresql-contrib (14+238) ...\n",
            "Setting up postgresql (14+238) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            " * Starting PostgreSQL 14 database server\n",
            "   ...done.\n",
            "CREATE ROLE\n",
            "CREATE DATABASE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psycopg2\n",
        "\n",
        "# Koneksi ke database\n",
        "conn = psycopg2.connect(\n",
        "    dbname=\"colabdb\",\n",
        "    user=\"colabuser\",\n",
        "    password=\"colabpass\",\n",
        "    host=\"localhost\",\n",
        "    port=\"5432\"\n",
        ")\n",
        "\n",
        "cur = conn.cursor()\n",
        "\n",
        "# Buat tabel\n",
        "cur.execute(\"\"\"\n",
        "DROP TABLE IF EXISTS sensor_data;\n",
        "CREATE TABLE sensor_data (\n",
        "    id SERIAL PRIMARY KEY,\n",
        "    waktu TIMESTAMP DEFAULT NOW(),\n",
        "    suhu FLOAT,\n",
        "    kelembaban FLOAT,\n",
        "    status TEXT DEFAULT 'normal'\n",
        ");\n",
        "\"\"\")\n",
        "\n",
        "# Buat stored procedure (fungsi untuk menambah data)\n",
        "cur.execute(\"\"\"\n",
        "CREATE OR REPLACE FUNCTION insert_sensor_data(p_suhu FLOAT, p_kelembaban FLOAT)\n",
        "RETURNS VOID AS $$\n",
        "BEGIN\n",
        "    INSERT INTO sensor_data (suhu, kelembaban)\n",
        "    VALUES (p_suhu, p_kelembaban);\n",
        "END;\n",
        "$$ LANGUAGE plpgsql;\n",
        "\"\"\")\n",
        "\n",
        "conn.commit()\n",
        "cur.close()\n",
        "conn.close()\n",
        "print(\"‚úÖ Stored procedure dan tabel berhasil dibuat!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ceniq2E7w-t0",
        "outputId": "4da14547-ae26-44ee-9ff4-665704720f7a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Stored procedure dan tabel berhasil dibuat!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conn = psycopg2.connect(\n",
        "    dbname=\"colabdb\",\n",
        "    user=\"colabuser\",\n",
        "    password=\"colabpass\",\n",
        "    host=\"localhost\",\n",
        "    port=\"5432\"\n",
        ")\n",
        "cur = conn.cursor()\n",
        "\n",
        "cur.execute(\"\"\"\n",
        "-- Fungsi yang dijalankan trigger\n",
        "CREATE OR REPLACE FUNCTION check_temperature()\n",
        "RETURNS TRIGGER AS $$\n",
        "BEGIN\n",
        "    IF NEW.suhu > 30 THEN\n",
        "        NEW.status := 'peringatan';\n",
        "    ELSE\n",
        "        NEW.status := 'normal';\n",
        "    END IF;\n",
        "    RETURN NEW;\n",
        "END;\n",
        "$$ LANGUAGE plpgsql;\n",
        "\n",
        "-- Buat trigger\n",
        "DROP TRIGGER IF EXISTS suhu_trigger ON sensor_data;\n",
        "CREATE TRIGGER suhu_trigger\n",
        "BEFORE INSERT ON sensor_data\n",
        "FOR EACH ROW\n",
        "EXECUTE FUNCTION check_temperature();\n",
        "\"\"\")\n",
        "\n",
        "conn.commit()\n",
        "cur.close()\n",
        "conn.close()\n",
        "print(\"‚úÖ Trigger berhasil dibuat!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8ajPVdbxHaS",
        "outputId": "1372d7fc-fc61-4893-c16b-12481fa45ce1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Trigger berhasil dibuat!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conn = psycopg2.connect(\n",
        "    dbname=\"colabdb\",\n",
        "    user=\"colabuser\",\n",
        "    password=\"colabpass\",\n",
        "    host=\"localhost\",\n",
        "    port=\"5432\"\n",
        ")\n",
        "cur = conn.cursor()\n",
        "\n",
        "# Panggil stored procedure\n",
        "cur.execute(\"SELECT insert_sensor_data(25.5, 60.2);\")  # normal\n",
        "cur.execute(\"SELECT insert_sensor_data(32.1, 58.7);\")  # peringatan\n",
        "conn.commit()\n",
        "\n",
        "# Lihat hasilnya\n",
        "cur.execute(\"SELECT * FROM sensor_data;\")\n",
        "for row in cur.fetchall():\n",
        "    print(row)\n",
        "\n",
        "cur.close()\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOvU5h3RxJp7",
        "outputId": "4c28ab15-f09b-4ada-9a7d-7a68056290a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, datetime.datetime(2025, 10, 20, 0, 28, 36, 26845), 25.5, 60.2, 'normal')\n",
            "(2, datetime.datetime(2025, 10, 20, 0, 28, 36, 26845), 32.1, 58.7, 'peringatan')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mongota (MongoDB tanpa server)"
      ],
      "metadata": {
        "id": "yEMHZHTj50FB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mongita\n",
        "from mongita import MongitaClientDisk\n",
        "\n",
        "client = MongitaClientDisk()  # mirip MongoDB lokal\n",
        "db = client[\"iot_db\"]\n",
        "col = db[\"sensor_data\"]\n",
        "\n",
        "col.insert_one({\"suhu\": 31.5, \"kelembaban\": 58.7})\n",
        "print(list(col.find()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djy-MRXcukqS",
        "outputId": "690be146-3b6d-4976-abec-08478f343e2a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mongita\n",
            "  Downloading mongita-1.2.0.tar.gz (54 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/54.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pymongo<5.0,>=3.0 (from mongita)\n",
            "  Downloading pymongo-4.15.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from mongita) (2.4.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0,>=3.0->mongita)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading pymongo-4.15.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mongita\n",
            "  Building wheel for mongita (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mongita: filename=mongita-1.2.0-py3-none-any.whl size=61258 sha256=b40dd0e435a3103ae27d236c96499cafcd598b2d292b4fe99b621521cd6a1882\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/bf/0d/6a2a625c704f15045f2e0286f8a819f2104eeaefb92cd42a4f\n",
            "Successfully built mongita\n",
            "Installing collected packages: dnspython, pymongo, mongita\n",
            "Successfully installed dnspython-2.8.0 mongita-1.2.0 pymongo-4.15.3\n",
            "[{'suhu': 31.5, 'kelembaban': 58.7, '_id': ObjectId('68f5824861fcda3361cf92cc')}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert satu dokumen\n",
        "col.insert_one({\"suhu\": 27.5, \"kelembaban\": 68.2, \"status\": \"normal\"})\n",
        "\n",
        "# Insert beberapa dokumen sekaligus\n",
        "col.insert_many([\n",
        "    {\"suhu\": 31.2, \"kelembaban\": 60.1, \"status\": \"peringatan\"},\n",
        "    {\"suhu\": 25.8, \"kelembaban\": 75.0, \"status\": \"normal\"},\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI4Ptn186WnA",
        "outputId": "04c3c3d0-4f2b-4737-eec1-ed48c4d8c068"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mongita.results.InsertManyResult at 0x793542cb9a90>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ambil semua data\n",
        "for doc in col.find():\n",
        "    print(doc)\n",
        "\n",
        "# Filter dengan kondisi\n",
        "for doc in col.find({\"status\": \"peringatan\"}):\n",
        "    print(\"üî•\", doc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M4en7Yu6J0Y",
        "outputId": "15fd971e-8fa1-48cb-f81b-3a755f844258"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'suhu': 31.5, 'kelembaban': 58.7, '_id': ObjectId('68f5824861fcda3361cf92cc')}\n",
            "{'suhu': 27.5, 'kelembaban': 68.2, 'status': 'normal', '_id': ObjectId('68f5824c61fcda3361cf92cf')}\n",
            "{'suhu': 31.2, 'kelembaban': 60.1, 'status': 'peringatan', '_id': ObjectId('68f5824c61fcda3361cf92d0')}\n",
            "{'suhu': 25.8, 'kelembaban': 75.0, 'status': 'normal', '_id': ObjectId('68f5824c61fcda3361cf92d1')}\n",
            "üî• {'suhu': 31.2, 'kelembaban': 60.1, 'status': 'peringatan', '_id': ObjectId('68f5824c61fcda3361cf92d0')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update satu dokumen\n",
        "col.update_one({\"suhu\": 31.2}, {\"$set\": {\"status\": \"normal\"}})\n",
        "\n",
        "# Update banyak data sekaligus\n",
        "col.update_many({\"kelembaban\": {\"$gt\": 70}}, {\"$set\": {\"catatan\": \"kelembaban tinggi\"}})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6w6k6G36gdH",
        "outputId": "534f1771-48e8-4d53-914b-520efa752a45"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mongita.results.UpdateResult at 0x793541a329f0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hapus satu dokumen\n",
        "col.delete_one({\"suhu\": 25.8})\n",
        "\n",
        "# Hapus semua data dengan kondisi tertentu\n",
        "col.delete_many({\"status\": \"normal\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9bnMRte6j1X",
        "outputId": "8afeb819-34eb-4170-bf21-65ae1554fb0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mongita.results.DeleteResult at 0x7935418b0bc0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data dengan suhu lebih dari 28\n",
        "for doc in col.find({\"suhu\": {\"$gt\": 28}}):\n",
        "    print(\"üî• Suhu tinggi:\", doc)\n",
        "\n",
        "# Data dengan kelembaban antara 60‚Äì70\n",
        "for doc in col.find({\"kelembaban\": {\"$gte\": 60, \"$lte\": 70}}):\n",
        "    print(\"üíß Rentang normal:\", doc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B6rHiwg6lNw",
        "outputId": "164ae542-4980-41ae-f40b-f53d0ae6f38a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî• Suhu tinggi: {'suhu': 31.5, 'kelembaban': 58.7, '_id': ObjectId('68f5824861fcda3361cf92cc')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def insert_sensor(suhu, kelembaban):\n",
        "    status = \"peringatan\" if suhu > 30 else \"normal\"\n",
        "    col.insert_one({\n",
        "        \"suhu\": suhu,\n",
        "        \"kelembaban\": kelembaban,\n",
        "        \"status\": status,\n",
        "        \"timestamp\": datetime.now()\n",
        "    })\n",
        "\n",
        "insert_sensor(32.5, 55)\n",
        "insert_sensor(26.4, 70)\n",
        "\n",
        "for doc in col.find():\n",
        "    print(doc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doedDUo_6y_H",
        "outputId": "431770d4-236f-4fe5-8216-3289916734e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'suhu': 31.5, 'kelembaban': 58.7, '_id': ObjectId('68f5824861fcda3361cf92cc')}\n",
            "{'suhu': 32.5, 'kelembaban': 55, 'status': 'peringatan', 'timestamp': datetime.datetime(2025, 10, 20, 0, 29, 16, 710315), '_id': ObjectId('68f5825c61fcda3361cf92d2')}\n",
            "{'suhu': 26.4, 'kelembaban': 70, 'status': 'normal', 'timestamp': datetime.datetime(2025, 10, 20, 0, 29, 16, 712938), '_id': ObjectId('68f5825c61fcda3361cf92d3')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "jIpfHe-V9THN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ambil semua data ke DataFrame\n",
        "df = pd.DataFrame(list(col.find()))\n",
        "\n",
        "# Agregasi manual seperti MongoDB pipeline\n",
        "agg = df.groupby(\"status\").agg({\n",
        "    \"suhu\": \"mean\",\n",
        "    \"kelembaban\": \"mean\",\n",
        "    \"_id\": \"count\"\n",
        "}).rename(columns={\"_id\": \"jumlah_data\"})\n",
        "\n",
        "print(agg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbR-QJYo9VIb",
        "outputId": "9ca67427-0a16-4ac7-ef71-4a4dd35a5894"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            suhu  kelembaban  jumlah_data\n",
            "status                                   \n",
            "normal      26.4        70.0            1\n",
            "peringatan  32.5        55.0            1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean\n",
        "\n",
        "def mongita_aggregate(collection, group_by_field, ops):\n",
        "    \"\"\"\n",
        "    Emulator aggregate sederhana untuk Mongita\n",
        "    :param collection: koleksi Mongita\n",
        "    :param group_by_field: field yang dijadikan grup (misal \"status\")\n",
        "    :param ops: dict operasi agregasi, misal {\"suhu\": \"avg\", \"kelembaban\": \"max\"}\n",
        "    \"\"\"\n",
        "    data = list(collection.find())\n",
        "    grouped = {}\n",
        "\n",
        "    # Kelompokkan data berdasarkan field\n",
        "    for doc in data:\n",
        "        key = doc.get(group_by_field, None)\n",
        "        if key not in grouped:\n",
        "            grouped[key] = []\n",
        "        grouped[key].append(doc)\n",
        "\n",
        "    results = []\n",
        "    for key, docs in grouped.items():\n",
        "        result = {\"_id\": key}\n",
        "        for field, op in ops.items():\n",
        "            values = [d.get(field, 0) for d in docs if field in d]\n",
        "            if not values:\n",
        "                result[field] = None\n",
        "            elif op == \"avg\":\n",
        "                result[field] = sum(values) / len(values)\n",
        "            elif op == \"sum\":\n",
        "                result[field] = sum(values)\n",
        "            elif op == \"min\":\n",
        "                result[field] = min(values)\n",
        "            elif op == \"max\":\n",
        "                result[field] = max(values)\n",
        "            elif op == \"count\":\n",
        "                result[field] = len(values)\n",
        "        results.append(result)\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "qT2bBBzi9-tL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hasil = mongita_aggregate(col, \"status\", {\n",
        "    \"suhu\": \"avg\",\n",
        "    \"kelembaban\": \"avg\"\n",
        "})\n",
        "for h in hasil:\n",
        "    print(h)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBZ6qqaA-AqB",
        "outputId": "1e3bbccb-9c2f-4430-ce82-c6b9f63ca385"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_id': None, 'suhu': 31.5, 'kelembaban': 58.7}\n",
            "{'_id': 'peringatan', 'suhu': 32.5, 'kelembaban': 55.0}\n",
            "{'_id': 'normal', 'suhu': 26.4, 'kelembaban': 70.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hasil = mongita_aggregate(col, \"status\", {\n",
        "    \"suhu\": \"sum\",\n",
        "    \"kelembaban\": \"sum\",\n",
        "    \"status\": \"count\"\n",
        "})\n",
        "for h in hasil:\n",
        "    print(h)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VvSwLim-HLK",
        "outputId": "9f1cd832-1f9c-47a0-9098-b31ede39bc6f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_id': None, 'suhu': 31.5, 'kelembaban': 58.7, 'status': None}\n",
            "{'_id': 'peringatan', 'suhu': 32.5, 'kelembaban': 55, 'status': 1}\n",
            "{'_id': 'normal', 'suhu': 26.4, 'kelembaban': 70, 'status': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hasil = mongita_aggregate(col, \"status\", {\n",
        "    \"suhu\": \"max\",\n",
        "    \"kelembaban\": \"min\"\n",
        "})\n",
        "for h in hasil:\n",
        "    print(h)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EP--fBK-K0_",
        "outputId": "0dbe0ff3-8e2a-4927-8202-882c3930d51e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_id': None, 'suhu': 31.5, 'kelembaban': 58.7}\n",
            "{'_id': 'peringatan', 'suhu': 32.5, 'kelembaban': 55}\n",
            "{'_id': 'normal', 'suhu': 26.4, 'kelembaban': 70}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean\n",
        "\n",
        "def mongita_aggregate_extended(collection, pipeline):\n",
        "    data = list(collection.find())\n",
        "\n",
        "    for stage in pipeline:\n",
        "        if \"$match\" in stage:\n",
        "            cond = stage[\"$match\"]\n",
        "            filtered = []\n",
        "            for doc in data:\n",
        "                include = True\n",
        "                for field, value in cond.items():\n",
        "                    # hanya dukung perbandingan dasar\n",
        "                    if isinstance(value, dict):\n",
        "                        if \"$gt\" in value and not (doc.get(field, 0) > value[\"$gt\"]):\n",
        "                            include = False\n",
        "                        if \"$lt\" in value and not (doc.get(field, 0) < value[\"$lt\"]):\n",
        "                            include = False\n",
        "                        if \"$gte\" in value and not (doc.get(field, 0) >= value[\"$gte\"]):\n",
        "                            include = False\n",
        "                        if \"$lte\" in value and not (doc.get(field, 0) <= value[\"$lte\"]):\n",
        "                            include = False\n",
        "                    else:\n",
        "                        if doc.get(field) != value:\n",
        "                            include = False\n",
        "                if include:\n",
        "                    filtered.append(doc)\n",
        "            data = filtered\n",
        "\n",
        "        elif \"$group\" in stage:\n",
        "            group_by = stage[\"$group\"][\"_id\"]\n",
        "            fields = {k: v for k, v in stage[\"$group\"].items() if k != \"_id\"}\n",
        "            grouped = {}\n",
        "            for doc in data:\n",
        "                key = doc.get(group_by)\n",
        "                grouped.setdefault(key, []).append(doc)\n",
        "            results = []\n",
        "            for key, docs in grouped.items():\n",
        "                out = {\"_id\": key}\n",
        "                for field, expr in fields.items():\n",
        "                    if isinstance(expr, dict):\n",
        "                        op, target = list(expr.items())[0]\n",
        "                        vals = [d.get(target, 0) for d in docs if target in d]\n",
        "                        if op == \"$avg\":\n",
        "                            out[field] = mean(vals) if vals else None\n",
        "                        elif op == \"$sum\":\n",
        "                            out[field] = sum(vals)\n",
        "                        elif op == \"$min\":\n",
        "                            out[field] = min(vals)\n",
        "                        elif op == \"$max\":\n",
        "                            out[field] = max(vals)\n",
        "                        elif op == \"$count\":\n",
        "                            out[field] = len(vals)\n",
        "                results.append(out)\n",
        "            data = results\n",
        "\n",
        "        elif \"$project\" in stage:\n",
        "            fields = stage[\"$project\"]\n",
        "            projected = []\n",
        "            for doc in data:\n",
        "                new_doc = {}\n",
        "                for field, include in fields.items():\n",
        "                    if include and field in doc:\n",
        "                        new_doc[field] = doc[field]\n",
        "                projected.append(new_doc)\n",
        "            data = projected\n",
        "\n",
        "        elif \"$sort\" in stage:\n",
        "            sort_field, direction = list(stage[\"$sort\"].items())[0]\n",
        "            reverse = direction == -1\n",
        "            data = sorted(data, key=lambda x: x.get(sort_field, 0), reverse=reverse)\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "ogPbgny8-cm4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tambahkan contoh data\n",
        "col.insert_many([\n",
        "    {\"device\": \"ESP32_A\", \"status\": \"normal\", \"suhu\": 26.3, \"kelembaban\": 70},\n",
        "    {\"device\": \"ESP32_A\", \"status\": \"normal\", \"suhu\": 27.1, \"kelembaban\": 68},\n",
        "    {\"device\": \"ESP32_A\", \"status\": \"peringatan\", \"suhu\": 33.5, \"kelembaban\": 58},\n",
        "    {\"device\": \"ESP32_B\", \"status\": \"normal\", \"suhu\": 25.8, \"kelembaban\": 72},\n",
        "    {\"device\": \"ESP32_B\", \"status\": \"peringatan\", \"suhu\": 31.2, \"kelembaban\": 60},\n",
        "    {\"device\": \"ESP32_B\", \"status\": \"normal\", \"suhu\": 24.9, \"kelembaban\": 73},\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdeUIQx8-i-x",
        "outputId": "ae892e3e-8655-4f0f-97d3-6efe2af29718"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mongita.results.InsertManyResult at 0x79352fb4fb30>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = [\n",
        "    {\"$match\": {\"device\": \"ESP32_A\"}},\n",
        "    {\"$group\": {\n",
        "        \"_id\": \"$status\",\n",
        "        \"avg_suhu\": {\"$avg\": \"suhu\"},\n",
        "        \"avg_kelembaban\": {\"$avg\": \"kelembaban\"},\n",
        "        \"jumlah\": {\"$count\": \"suhu\"}\n",
        "    }},\n",
        "    {\"$project\": {\"_id\": 1, \"avg_suhu\": 1, \"avg_kelembaban\": 1, \"jumlah\": 1}},\n",
        "    {\"$sort\": {\"avg_suhu\": -1}}\n",
        "]\n",
        "\n",
        "hasil = mongita_aggregate_extended(col, pipeline)\n",
        "for h in hasil:\n",
        "    print(h)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qmwUm4P-feh",
        "outputId": "b2667c7c-570e-41e9-9a3b-8e085c5cae35"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_id': None, 'avg_suhu': 28.96666666666667, 'avg_kelembaban': 65.33333333333333, 'jumlah': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = [\n",
        "    {\"$match\": {\"suhu\": {\"$gte\": 25, \"$lte\": 35}}},\n",
        "    {\"$group\": {\n",
        "        \"_id\": \"$device\",\n",
        "        \"max_suhu\": {\"$max\": \"suhu\"},\n",
        "        \"min_kelembaban\": {\"$min\": \"kelembaban\"}\n",
        "    }},\n",
        "    {\"$sort\": {\"max_suhu\": -1}}\n",
        "]\n",
        "\n",
        "for doc in mongita_aggregate_extended(col, pipeline):\n",
        "    print(doc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzRkfKyE-u3Y",
        "outputId": "146f45f0-bf32-4111-8a16-96fe0605e48b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_id': None, 'max_suhu': 33.5, 'min_kelembaban': 55}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = [\n",
        "    {\"$project\": {\"device\": 1, \"suhu\": 1, \"status\": 1}},\n",
        "    {\"$sort\": {\"suhu\": -1}}\n",
        "]\n",
        "\n",
        "for doc in mongita_aggregate_extended(col, pipeline):\n",
        "    print(doc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_wl8QMg-whZ",
        "outputId": "28eed94e-f517-46b5-defa-2b705a093af8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'device': 'ESP32_A', 'suhu': 33.5, 'status': 'peringatan'}\n",
            "{'suhu': 32.5, 'status': 'peringatan'}\n",
            "{'suhu': 31.5}\n",
            "{'device': 'ESP32_B', 'suhu': 31.2, 'status': 'peringatan'}\n",
            "{'device': 'ESP32_A', 'suhu': 27.1, 'status': 'normal'}\n",
            "{'suhu': 26.4, 'status': 'normal'}\n",
            "{'device': 'ESP32_A', 'suhu': 26.3, 'status': 'normal'}\n",
            "{'device': 'ESP32_B', 'suhu': 25.8, 'status': 'normal'}\n",
            "{'device': 'ESP32_B', 'suhu': 24.9, 'status': 'normal'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col.drop()        # hapus koleksi\n",
        "db.drop_database(\"iot_db\")  # hapus seluruh database"
      ],
      "metadata": {
        "id": "PtE4SUwm66DH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "863a5f04-22a9-4dab-ed5a-2a479faa8713"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MongitaNotImplementedError",
          "evalue": "Collection.drop is not yet implemented. You can help.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMongitaNotImplementedError\u001b[0m                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1145659244.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# hapus koleksi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iot_db\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# hapus seluruh database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mongita/collection.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mMongitaNotImplementedError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_depr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Collection\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNIMPLEMENTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMongitaNotImplementedError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Collection\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         return Collection(collection_name=self.name + '.' + attr,\n\u001b[1;32m    666\u001b[0m                           database=self.database)\n",
            "\u001b[0;31mMongitaNotImplementedError\u001b[0m: Collection.drop is not yet implemented. You can help."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semi Structured Data"
      ],
      "metadata": {
        "id": "R1hUF3tJ6KiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Generate Random IoT Data and Write to\n",
        "# JSON, CSV, and XML files\n",
        "# ==========================================\n",
        "\n",
        "import json\n",
        "import csv\n",
        "import xml.etree.ElementTree as ET\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# ------------------------------------------\n",
        "# 1Ô∏è‚É£ Fungsi pembuat data acak\n",
        "# ------------------------------------------\n",
        "def generate_random_data(n=10):\n",
        "    data = []\n",
        "    locations = ['Greenhouse_1', 'Greenhouse_2', 'Hydroponic_A', 'SoilLab_B']\n",
        "    for i in range(n):\n",
        "        record = {\n",
        "            \"device_id\": f\"ESP32_{i+1:03d}\",\n",
        "            \"timestamp\": (datetime.now() - timedelta(minutes=i*5)).isoformat(),\n",
        "            \"location\": random.choice(locations),\n",
        "            \"temperature\": round(random.uniform(25.0, 35.0), 2),\n",
        "            \"humidity\": round(random.uniform(50.0, 80.0), 2),\n",
        "            \"soil_moisture\": random.randint(400, 700)\n",
        "        }\n",
        "        data.append(record)\n",
        "    return data\n",
        "\n",
        "# Generate 20 baris data acak\n",
        "sensor_data = generate_random_data(20)\n",
        "\n",
        "# ------------------------------------------\n",
        "# 2Ô∏è‚É£ Menulis ke file JSON\n",
        "# ------------------------------------------\n",
        "with open('data.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(sensor_data, f, indent=4)\n",
        "print(\"‚úÖ File JSON berhasil dibuat: data.json\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 3Ô∏è‚É£ Menulis ke file CSV\n",
        "# ------------------------------------------\n",
        "with open('data.csv', 'w', newline='', encoding='utf-8') as f:\n",
        "    fieldnames = ['device_id', 'timestamp', 'location', 'temperature', 'humidity', 'soil_moisture']\n",
        "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for rec in sensor_data:\n",
        "        writer.writerow(rec)\n",
        "print(\"‚úÖ File CSV berhasil dibuat: data.csv\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 4Ô∏è‚É£ Menulis ke file XML\n",
        "# ------------------------------------------\n",
        "root = ET.Element(\"sensors\")\n",
        "\n",
        "for rec in sensor_data:\n",
        "    sensor_elem = ET.SubElement(root, \"sensor\")\n",
        "    ET.SubElement(sensor_elem, \"device_id\").text = rec[\"device_id\"]\n",
        "    ET.SubElement(sensor_elem, \"timestamp\").text = rec[\"timestamp\"]\n",
        "    ET.SubElement(sensor_elem, \"location\").text = rec[\"location\"]\n",
        "    ET.SubElement(sensor_elem, \"temperature\").text = str(rec[\"temperature\"])\n",
        "    ET.SubElement(sensor_elem, \"humidity\").text = str(rec[\"humidity\"])\n",
        "    ET.SubElement(sensor_elem, \"soil_moisture\").text = str(rec[\"soil_moisture\"])\n",
        "\n",
        "tree = ET.ElementTree(root)\n",
        "tree.write(\"data.xml\", encoding=\"utf-8\", xml_declaration=True)\n",
        "print(\"‚úÖ File XML berhasil dibuat: data.xml\")\n",
        "\n",
        "print(\"\\nüìä Semua file (JSON, CSV, XML) berhasil ditulis dengan data acak!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XUK9zldutJF",
        "outputId": "dba46fd4-0e4a-4cd0-c843-b93f3dd61212"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ File JSON berhasil dibuat: data.json\n",
            "‚úÖ File CSV berhasil dibuat: data.csv\n",
            "‚úÖ File XML berhasil dibuat: data.xml\n",
            "\n",
            "üìä Semua file (JSON, CSV, XML) berhasil ditulis dengan data acak!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8CqiTpSui_I",
        "outputId": "1dd5f946-9757-4cab-87df-4b5c0fed63b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data loaded successfully to OLAP database\n",
            "\n",
            "=== OLAP Aggregation Results ===\n",
            "\n",
            "üìä Average Temperature per Location:\n",
            "  Greenhouse_1: 29.85 ¬∞C\n",
            "  Greenhouse_2: 31.13 ¬∞C\n",
            "  Hydroponic_A: 30.93 ¬∞C\n",
            "  SoilLab_B: 29.02 ¬∞C\n",
            "\n",
            "‚öôÔ∏è Log Events by Level:\n",
            "\n",
            "üìà Pivot Table (Average Temp):\n",
            "               temperature\n",
            "location                 \n",
            "Greenhouse_1    29.853333\n",
            "Greenhouse_2    31.133333\n",
            "Hydroponic_A    30.927143\n",
            "SoilLab_B       29.017143\n",
            "\n",
            "‚úÖ OLAP processing complete.\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# OLAP Processing for Semi-Structured Data\n",
        "# Using SQLAlchemy (SQLite backend)\n",
        "# ============================================\n",
        "\n",
        "import json\n",
        "import csv\n",
        "import xml.etree.ElementTree as ET\n",
        "from sqlalchemy import create_engine, Column, Integer, Float, String, DateTime, func\n",
        "from sqlalchemy.orm import sessionmaker, declarative_base\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "# --------------------------------------------\n",
        "# 1Ô∏è‚É£ Setup Database (OLAP layer)\n",
        "# --------------------------------------------\n",
        "Base = declarative_base()\n",
        "\n",
        "class SensorData(Base):\n",
        "    __tablename__ = 'sensor_data'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    device_id = Column(String)\n",
        "    location = Column(String)\n",
        "    timestamp = Column(DateTime)\n",
        "    temperature = Column(Float)\n",
        "    humidity = Column(Float)\n",
        "    soil_moisture = Column(Float)\n",
        "\n",
        "class ProductionData(Base):\n",
        "    __tablename__ = 'production_data'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    product = Column(String)\n",
        "    quantity = Column(Float)\n",
        "    month = Column(String)\n",
        "    year = Column(Integer)\n",
        "\n",
        "class LogEvent(Base):\n",
        "    __tablename__ = 'log_event'\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    level = Column(String)\n",
        "    timestamp = Column(DateTime)\n",
        "    message = Column(String)\n",
        "\n",
        "# --------------------------------------------\n",
        "# 2Ô∏è‚É£ Connect Database\n",
        "# --------------------------------------------\n",
        "engine = create_engine('sqlite:///olap_data.db')  # ganti ke postgresql://user:pass@host/dbname jika perlu\n",
        "Base.metadata.create_all(engine)\n",
        "Session = sessionmaker(bind=engine)\n",
        "session = Session()\n",
        "\n",
        "# --------------------------------------------\n",
        "# 3Ô∏è‚É£ Extract + Transform Semi-Structured Data\n",
        "# --------------------------------------------\n",
        "\n",
        "# 3.1 JSON (IoT Sensor)\n",
        "with open('data.json', 'r') as f:\n",
        "    json_data = json.load(f)\n",
        "\n",
        "for item in json_data:\n",
        "    record = SensorData(\n",
        "        device_id=item.get('device_id'),\n",
        "        location=item.get('location'),\n",
        "        timestamp=datetime.fromisoformat(item.get('timestamp').replace('Z','')),\n",
        "        temperature=item.get('temperature'),\n",
        "        humidity=item.get('humidity'),\n",
        "        soil_moisture=item.get('soil_moisture')\n",
        "    )\n",
        "    session.add(record)\n",
        "\n",
        "# 3.2 CSV (Sensor Data - currently data.csv contains sensor data)\n",
        "with open('data.csv', newline='') as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "        record = SensorData(\n",
        "            device_id=row['device_id'],\n",
        "            location=row['location'],\n",
        "            timestamp=datetime.fromisoformat(row['timestamp'].replace('Z','')),\n",
        "            temperature=float(row['temperature']),\n",
        "            humidity=float(row['humidity']),\n",
        "            soil_moisture=float(row['soil_moisture'])\n",
        "        )\n",
        "        session.add(record)\n",
        "\n",
        "# 3.3 XML (Log Events)\n",
        "tree = ET.parse('data.xml')\n",
        "root = tree.getroot()\n",
        "\n",
        "for log in root.findall('log'):\n",
        "    record = LogEvent(\n",
        "        level=log.findtext('level'),\n",
        "        timestamp=datetime.fromisoformat(log.findtext('timestamp').replace('Z','')),\n",
        "        message=log.findtext('message')\n",
        "    )\n",
        "    session.add(record)\n",
        "\n",
        "session.commit()\n",
        "print(\"‚úÖ Data loaded successfully to OLAP database\")\n",
        "\n",
        "# --------------------------------------------\n",
        "# 4Ô∏è‚É£ OLAP Queries (Aggregations)\n",
        "# --------------------------------------------\n",
        "\n",
        "print(\"\\n=== OLAP Aggregation Results ===\")\n",
        "\n",
        "# 4.1 Average temperature per location\n",
        "avg_temp = (\n",
        "    session.query(SensorData.location, func.avg(SensorData.temperature))\n",
        "    .group_by(SensorData.location)\n",
        "    .all()\n",
        ")\n",
        "print(\"\\nüìä Average Temperature per Location:\")\n",
        "for loc, avg in avg_temp:\n",
        "    print(f\"  {loc}: {avg:.2f} ¬∞C\")\n",
        "\n",
        "# 4.2 Total production per year - This query will not work as there is no production data loaded\n",
        "# total_prod = (\n",
        "#     session.query(ProductionData.year, func.sum(ProductionData.quantity))\n",
        "#     .group_by(ProductionData.year)\n",
        "#     .all()\n",
        "# )\n",
        "# print(\"\\nüè≠ Total Production per Year:\")\n",
        "# for year, total in total_prod:\n",
        "#     print(f\"  {year}: {total:.0f} units\")\n",
        "\n",
        "# 4.3 Count log events by level\n",
        "log_count = (\n",
        "    session.query(LogEvent.level, func.count(LogEvent.id))\n",
        "    .group_by(LogEvent.level)\n",
        "    .all()\n",
        ")\n",
        "print(\"\\n‚öôÔ∏è Log Events by Level:\")\n",
        "for level, count in log_count:\n",
        "    print(f\"  {level}: {count} entries\")\n",
        "\n",
        "# --------------------------------------------\n",
        "# 5Ô∏è‚É£ Export Aggregation to Pandas DataFrame\n",
        "# --------------------------------------------\n",
        "df_sensor = pd.read_sql(session.query(SensorData).statement, session.bind)\n",
        "# df_prod = pd.read_sql(session.query(ProductionData).statement, session.bind) # Commenting out as no production data is loaded\n",
        "df_log = pd.read_sql(session.query(LogEvent).statement, session.bind)\n",
        "\n",
        "# Example: create OLAP-style pivot table\n",
        "pivot_temp = df_sensor.pivot_table(values='temperature', index='location', aggfunc='mean')\n",
        "print(\"\\nüìà Pivot Table (Average Temp):\\n\", pivot_temp)\n",
        "\n",
        "print(\"\\n‚úÖ OLAP processing complete.\")"
      ]
    }
  ]
}